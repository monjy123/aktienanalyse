#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
FMP Historical Market Capitalization Loader

L√§dt historische Marktkapitalisierung von FMP API f√ºr alle ISINs in tickerlist.
Verwendet Threading f√ºr parallele API-Requests.

Workflow:
1. ISINs aus tickerlist laden
2. ISIN ‚Üí Ticker mappen via FMP API (nutzt bestehendes Mapping falls vorhanden)
3. Historical Market Cap laden (parallel)
4. In fmp_historical_market_cap speichern
"""

import sys
import os
import time
import logging
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

sys.path.insert(0, str(Path(__file__).parent.parent))

import requests
from tqdm import tqdm
from dotenv import load_dotenv
from mysql.connector import Error as MySQLError
from db import get_connection

# Thread-lokaler Storage f√ºr DB-Connections
thread_local = threading.local()

# .env laden
load_dotenv(Path(__file__).parent.parent / ".env")

FMP_API_KEY = os.getenv("FMP_API_KEY")
FMP_BASE_URL = "https://financialmodelingprep.com"

# Anzahl paralleler Threads (FMP erlaubt typischerweise 10-30 parallele Requests)
MAX_WORKERS = 10

# Logging Setup
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler(Path(__file__).parent / "fmp_market_cap_loader.log"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)


# =============================================================================
# SQL Statements
# =============================================================================

CREATE_MARKET_CAP_TABLE = """
CREATE TABLE IF NOT EXISTS raw_data.fmp_historical_market_cap (
    id INT AUTO_INCREMENT PRIMARY KEY,

    -- Identifikation
    ticker VARCHAR(20) NOT NULL,
    isin VARCHAR(12),
    stock_index VARCHAR(50),
    company_name VARCHAR(255),

    -- Daten
    date DATE NOT NULL,
    market_cap BIGINT,

    -- Metadata
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,

    UNIQUE KEY unique_entry (ticker, date),
    INDEX idx_ticker (ticker),
    INDEX idx_isin (isin),
    INDEX idx_stock_index (stock_index),
    INDEX idx_date (date),
    INDEX idx_ticker_date (ticker, date)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4;
"""


# =============================================================================
# API Functions
# =============================================================================

def get_session():
    """Thread-lokale requests Session f√ºr Connection Pooling."""
    if not hasattr(thread_local, "session"):
        thread_local.session = requests.Session()
    return thread_local.session


def api_request(endpoint, params=None, max_retries=3):
    """API Request mit Retry (ohne k√ºnstliches Rate Limiting bei Threading)."""
    if params is None:
        params = {}
    params["apikey"] = FMP_API_KEY

    url = f"{FMP_BASE_URL}{endpoint}"
    session = get_session()

    for attempt in range(max_retries):
        try:
            response = session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            if attempt < max_retries - 1:
                wait = 2 ** attempt
                logger.warning(f"API Fehler (Versuch {attempt+1}): {e}. Warte {wait}s...")
                time.sleep(wait)
            else:
                logger.error(f"API Fehler nach {max_retries} Versuchen: {e}")
                return None
    return None


def search_isin(isin):
    """Suche Ticker f√ºr ISIN via FMP API."""
    data = api_request(f"/stable/search-isin", {"isin": isin})
    if data and len(data) > 0:
        return data[0]  # Erstes Ergebnis
    return None


def get_historical_market_cap(ticker):
    """Lade historische Marktkapitalisierung (30+ Jahre)."""
    return api_request(f"/stable/historical-market-capitalization", {
        "symbol": ticker,
        "from": "1990-01-01"  # 30+ Jahre historische Daten
    })


# =============================================================================
# Data Processing
# =============================================================================

def get_existing_mapping(cur, isin):
    """Hole bestehendes Ticker-Mapping aus der DB."""
    cur.execute("""
        SELECT ticker, company_name, exchange
        FROM raw_data.fmp_ticker_mapping
        WHERE isin = %s
        LIMIT 1
    """, (isin,))
    result = cur.fetchone()
    if result:
        return {
            "symbol": result[0],
            "name": result[1],
            "exchange": result[2]
        }
    return None


def save_market_cap(cur, ticker, isin, stock_index, company_name, records):
    """Speichere Historical Market Cap."""
    if not records:
        return 0

    sql = """
    INSERT INTO raw_data.fmp_historical_market_cap (
        ticker, isin, stock_index, company_name,
        date, market_cap
    ) VALUES (%s, %s, %s, %s, %s, %s)
    ON DUPLICATE KEY UPDATE
        isin = VALUES(isin),
        stock_index = VALUES(stock_index),
        company_name = VALUES(company_name),
        market_cap = VALUES(market_cap),
        updated_at = NOW()
    """

    count = 0
    for r in records:
        if not r.get("date"):
            continue

        values = (
            ticker,
            isin,
            stock_index,
            company_name,
            r.get("date"),
            r.get("marketCap"),
        )

        try:
            cur.execute(sql, values)
            count += 1
        except MySQLError as e:
            logger.warning(f"Fehler beim Speichern {ticker} {r.get('date')}: {e}")

    return count


# =============================================================================
# Main
# =============================================================================

def fetch_market_cap_for_ticker(isin, stock_index, existing_mappings):
    """
    Fetch Market Cap f√ºr einen Ticker (wird in Thread ausgef√ºhrt).
    Gibt (isin, stock_index, ticker, company_name, data, error) zur√ºck.
    """
    # 1. Zuerst bestehendes Mapping pr√ºfen
    mapping = existing_mappings.get(isin)

    # Falls kein Mapping existiert, via API suchen
    if not mapping:
        mapping = search_isin(isin)
        if not mapping:
            return (isin, stock_index, None, None, None, "Kein Ticker gefunden")

    ticker = mapping.get("symbol")
    company_name = mapping.get("name")

    if not ticker:
        return (isin, stock_index, None, None, None, "Leerer Ticker")

    # 2. Historical Market Cap laden
    market_cap_data = get_historical_market_cap(ticker)

    if not market_cap_data:
        return (isin, stock_index, ticker, company_name, None, "Keine Daten")

    return (isin, stock_index, ticker, company_name, market_cap_data, None)


def main():
    print("=" * 60)
    print("FMP HISTORICAL MARKET CAP LOADER")
    print(f"(mit {MAX_WORKERS} parallelen Threads)")
    print("=" * 60)

    if not FMP_API_KEY:
        print("FEHLER: FMP_API_KEY nicht in .env gefunden!")
        return

    conn = None
    cur = None

    try:
        # DB Verbindung
        print("\nVerbinde zur Datenbank...")
        conn = get_connection(autocommit=False)
        cur = conn.cursor()
        print("Verbunden!")

        # Tabelle erstellen
        print("\nErstelle Tabelle...")
        cur.execute(CREATE_MARKET_CAP_TABLE)
        conn.commit()
        print("Tabelle erstellt!")

        # ISINs laden
        print("\nLade ISINs aus tickerlist...")
        cur.execute("""
            SELECT DISTINCT isin, stock_index
            FROM tickerdb.tickerlist
            WHERE isin IS NOT NULL AND isin != ''
        """)
        isins = cur.fetchall()
        print(f"{len(isins)} ISINs geladen!")

        # Bestehende Mappings vorladen (spart API-Calls)
        print("\nLade bestehende Ticker-Mappings...")
        cur.execute("""
            SELECT isin, ticker, company_name, exchange
            FROM raw_data.fmp_ticker_mapping
            WHERE isin IS NOT NULL
        """)
        existing_mappings = {}
        for row in cur.fetchall():
            existing_mappings[row[0]] = {
                "symbol": row[1],
                "name": row[2],
                "exchange": row[3]
            }
        print(f"{len(existing_mappings)} Mappings geladen!")

        # Statistik
        success_count = 0
        failed_isins = []
        total_records = 0

        # Market Cap laden mit Threading
        print("\n" + "=" * 60)
        print("Lade Historical Market Capitalization (parallel)...")
        print("=" * 60)

        # ThreadPoolExecutor f√ºr parallele API-Requests
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            # Alle Tasks submitten
            futures = {
                executor.submit(fetch_market_cap_for_ticker, isin, stock_index, existing_mappings): (isin, stock_index)
                for isin, stock_index in isins
            }

            # Ergebnisse verarbeiten mit Progress Bar
            with tqdm(total=len(futures), desc="Market Cap") as pbar:
                for future in as_completed(futures):
                    try:
                        isin, stock_index, ticker, company_name, data, error = future.result()

                        if error:
                            failed_isins.append((isin, stock_index, error))
                        elif data:
                            # Daten in DB speichern (sequentiell, da MySQL-Cursor nicht thread-safe)
                            count = save_market_cap(cur, ticker, isin, stock_index, company_name, data)
                            success_count += 1
                            total_records += count

                            # Commit nach jedem erfolgreichen Save
                            if success_count % 50 == 0:
                                conn.commit()

                    except Exception as e:
                        isin, stock_index = futures[future]
                        failed_isins.append((isin, stock_index, str(e)))
                        logger.error(f"Fehler bei {isin}: {e}")

                    pbar.update(1)

        # Finaler Commit
        conn.commit()

        # Finale Statistik aus DB
        print("\n" + "=" * 60)
        print("FERTIG - STATISTIK")
        print("=" * 60)

        # Anzahl Ticker mit Daten
        cur.execute("""
            SELECT COUNT(DISTINCT ticker)
            FROM raw_data.fmp_historical_market_cap
        """)
        ticker_with_data = cur.fetchone()[0]

        # Gesamt Zeilen
        cur.execute("SELECT COUNT(*) FROM raw_data.fmp_historical_market_cap")
        total_rows = cur.fetchone()[0]

        # Datum Range
        cur.execute("""
            SELECT MIN(date), MAX(date)
            FROM raw_data.fmp_historical_market_cap
        """)
        date_range = cur.fetchone()

        # Ausgabe
        total_isins = len(isins)
        print(f"\nüìä Gesamt ISINs:           {total_isins:,}")
        print(f"‚úÖ Erfolgreich geladen:    {success_count:,} ({success_count*100/total_isins:.1f}%)")
        print(f"‚ùå Fehlgeschlagen:         {len(failed_isins):,} ({len(failed_isins)*100/total_isins:.1f}%)")
        print(f"\nüìà Ticker mit Daten:       {ticker_with_data:,}")
        print(f"üìÑ Gesamt Datens√§tze:      {total_rows:,}")

        if date_range[0] and date_range[1]:
            print(f"üìÖ Zeitraum:               {date_range[0]} bis {date_range[1]}")

        print("\nüìä Datens√§tze pro Index:")
        cur.execute("""
            SELECT stock_index, COUNT(*) as cnt, COUNT(DISTINCT ticker) as tickers
            FROM raw_data.fmp_historical_market_cap
            GROUP BY stock_index
            ORDER BY cnt DESC
        """)
        for stock_idx, cnt, tickers in cur.fetchall():
            print(f"   {stock_idx:20} {cnt:>10,} Zeilen ({tickers} Ticker)")

        if failed_isins:
            print(f"\n‚ö†Ô∏è  Fehlgeschlagene ISINs: {len(failed_isins):,} (erste 20):")
            for isin, idx, reason in failed_isins[:20]:
                print(f"   {isin} ({idx}): {reason}")

    except MySQLError as e:
        print(f"Datenbankfehler: {e}")
        if conn:
            conn.rollback()
    except Exception as e:
        print(f"Fehler: {e}")
        logger.exception("Unerwarteter Fehler")
    finally:
        if cur:
            cur.close()
        if conn:
            conn.close()
        print("\nVerbindung geschlossen.")


if __name__ == "__main__":
    main()
